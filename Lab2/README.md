## Αναφορά Δεύτερου Εργαστηρίου
### Αρχιτεκτονική Υπολογιστών

* Σε αυτήν την άσκηση γίνεται προσομοίωση των [SPEC CPU2006 Benchmarks](https://www.spec.org/cpu2006/) στο [gem5](https://www.gem5.org). 

* Συγκεκριμένα, προσομοιώνονται τα: **401.bzip2**, **429.mcf**, **458.sjeng**, **470.lbm** και **456.hmmer** για διάφορες τιμές συχνότητας επεξεργαστή και διαφορετικές αρχιτεκτονικές μνήμης.

* Έπειτα, γίνεται μία προσπάθεια για βελτιστοποίηση της επιλογής της αρχιτεκτονικής μνήμης για κάθε _Benchmark_, με αξιοποίηση των στατιστικών από τις προσομοιώσεις στο gem5 και πληροφοριών από την βιβλιογραφία. 

* Τέλος, δημιουργείται μία συνάρτηση κόστους για τις επιλογές του παραπάνω βήματος.  


## Βήμα 1
1. Tα **default** στοιχεία του επεξεργαστή βρέθηκαν στο αρχείο _config.ini_ της κάθε προσομοίωσης.
**Συγκεκριμένα:**

* **dcache** από το system.cpu.dcache.
```
size=65536
assoc=2
```
* **icache** από το system.cpu.icache.
```
size=32768
assoc=2
```
* **l2cache** από το system.l2.
```
size=2097152
assoc=8
```
* **cache line size** από το system.
```
cache_line_size=64
```

2. Καταγραφή αποτελεσμάτων benchmarks για **default** τιμές (2GHz cpu-clock).

|                       |   bzip  |   mcf  |  hmmer |  sjeng  |   libm  |
|:---------------------:|:-------:|:------:|:------:|:-------:|:-------:|
| system.cpu.cpi        |  1.679650 | 1.299095 | 1.187917 | 10.270554 |  3.4934 |
| sim_seconds           |  0.083982 | 0.064955 | 0.059396 | 0.513528 | 0.174671 |
| system.cpu.dcache.overall_miss_rate::total | 0.014798 | 0.002108 | 0.001637 |  0.121831 | 0.060972 |
|system.cpu.icache.overall_miss_rate::total |  0.000077 | 0.023612 | 0.000221 | 0.000020 | 0.000094 |
| system.l2.overall_miss_rate::total| 0.282163 | 0.055046 | 0.077760 | 0.999972 | 0.999944 |  

Παρακάτω φαίνονται τα στοιχεία αυτού του πίνακα στα ακόλουθα διαγράμματα:


![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/dl1.jpg)
![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/il1.jpg)
![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/L2.jpg)
![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/secs.jpg)
![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/cpi-def.jpg)

* Παρατηρούμε ότι το CPI και τα simulated_seconds ακολουθούν το ίδιο μοτίβο, αναμενόμενο, καθώς είναι και τα δύο μέτρο απόδοσης και εφόσον συγκρίνονται υπό όμοια συχνότητα ρολογίου, αναμένεται να έχουν την ίδια συμπεριφορά. Επίσης, τα misses στην data cache φαίνεται να ακολουθούν και αυτά το ίδιο μοτίβο, κατί που εξηγείται καθώς διαδραματίζουν σημαντικό ρόλο στην επίδοση του συστήματος. Ακόμα, τα misses της L2 φαίνεται να είναι σε υψηλά σχετικά ποσοστά, όμως δεν θα πρέπει να ξεχνάμε ότι ένα μικρό ποσοστό των προσπελάσεων της μνήμης καταλήγουν σε αυτό το επίπεδο cache, όπως φαίνεται και από το miss rate της L1 Data και Instruction Cache. Τέλος, όλα σχεδόν τα προγράμματα έχουν αμελητέο instruction cache miss rate, εκτός από ένα. Αυτό, μπορεί να οφείλεται στο γεγονός ότι τα πιο πολλά προγράμματα περιέχουν λούπες και έτσι επαναλμβάνουν τις ίδιες εντολές είτε στο γεγονός ότι απουσιάζουν εντολές branch, με αποτέλεσμα να μην διακόπτεται η ροή της εκτέλεσης.  

3. 

* Mε αλλαγή της συχνότητας του επεξεργαστή στο **1 GHz.**

|                       |   bzip  |   mcf  |  hmmer |  sjeng  |   libm  |
|:---------------------:|:-------:|:------:|:------:|:-------:|:-------:|
| system.cpu.cpi        |  1.610247 | 1.279422 | 1.185304 | 7.040561 |  2.623265 |
| sim_seconds           |  0.161025 | 0.12794 | 0.118530 | 0.704056 | 0.262327 |
| system.cpu.dcache.overall_miss_rate::total | 0.014675 | 0.002108 | 0.001629 |  0.121831 | 0.060971 |
|system.cpu.icache.overall_miss_rate::total |  0.000077 | 0.023627 | 0.000221 | 0.000020 |  0.000094 |
| system.l2.overall_miss_rate::total| 0.282157 | 0.055046 | 0.077747 | 0.999972 | 0.999944 |

* Mε αλλαγή της συχνότητας του επεξεργαστή στα **3 GHz.**

|                       |   bzip  |   mcf  |  hmmer |  sjeng  |   libm  |
|:---------------------:|:-------:|:------:|:------:|:-------:|:-------:|
| system.cpu.cpi        |  1.753291 | 1.317329 | 1.190581 | 13.508136 |  4.39737 |
| sim_seconds           |  0.058385 | 0.043867 | 0.039646 | 0.449821 |  0.146433 |
| system.cpu.dcache.overall_miss_rate::total |  0.014932 | 0.002108 | 0.001637 | 0.121831 |  0.060972 |
|system.cpu.icache.overall_miss_rate::total |  0.000077 | 0.023609 | 0.000221 | 0.000020 | 0.000094 |
| system.l2.overall_miss_rate::total| 0.282166 | 0.055046 | 0.077761 | 0.999972 | 0.999944 |

* Το είναι το ρολόι που χρησιμοποιούν τα blocks που τρέχουν με τη συχνότητα του επεξεργαστή, ενώ το είναι το ρολόι που χρησιμοποιούν τα blocks που τρέχουν με την ταχύτητα του συστήματος. Ο λόγος ύπαρξης δύο ρολογιών είναι για λόγους συγχρονισμού των πιο γρήγορων τμημάτων του συστήματος (επεξεργαστής) με τα πιο αργά (π.χ. μνήμες).
_Πηγή_: [https://www.gem5.org/documentation/learning_gem5/part1/example_configs/](https://www.gem5.org/documentation/learning_gem5/part1/example_configs/)

* Πράγματι, αναζητώντας στο _congig.json_ πληροφορίες για το clock, βλέπουμε ότι τόσο οι πυρήνες, όσο και οι caches χρονίζονται στο cpu_clock ενώ η μνήμη DRAM στο system_clock.

* Τέλος, παρατηρώντας τα αποτελέσματα για κάθε benchmark, βλέπουμε ότι αυξάνοντας τη συχνότητα του επεξεργαστή, υπάρχει μείωση του χρόνου εκτέλεσης των προγραμμάτων αλλά όχι με γραμμικό scaling. Δηλαδή από τα 1 στα 2 GHz η αύξηση της ταχύτητας είναι μεγαλύτερη από ότι από τα 2 στα 3 GHz. Αυτό μπορεί να συμβαίνει επειδή η ύπαρξη και του ρολογιού του συστήματος καθιστά αδύνατο η μνήμη να μπορεί να ακολουθήσει τη ταχύτητα του επεξεργαστή, με αποτέλεσμα κάθε φορά που χρειάζεται να την προσπελαύνουμε να χάνουμε τον ίδιο χρόνο ανεξαρτήτως cpu_clock. Έτσι, η αύξηση της συχνότητας του επεξεργαστή βελτιώνει την απόδοση, αλλά πιθανόν να οδηγεί σε κορεσμό από μία συχνότητα και μετά. 

4.

* Mε αλλαγή της μνήμης DRAM σε **DDR3_2133_8x8**

|                       |   bzip  |   mcf  |  hmmer |  sjeng  |   libm  |
|:---------------------:|:-------:|:------:|:------:|:-------:|:-------:|
| system.cpu.cpi        |  1.672175 | 1.299095 | 1.187722 | 9.862562 |  3.430593 |
| sim_seconds           | 0.083609 | 0.064955 | 0.059386 | 0.493128 | 0.171530 |
| system.cpu.dcache.overall_miss_rate::total |  0.014795 | 0.002108 | 0.001637 |  0.121831 |  0.060972 |
|system.cpu.icache.overall_miss_rate::total |  0.000077 | 0.023612 | 0.000221 | 0.000020 |  0.000094 |
| system.l2.overall_miss_rate::total| 0.282159 | 0.055046 | 0.077760 | 0.999972 | 0.999944 | 

* Παρατηρούμε μία ελάχιστη μείωση του χρόνου εκτέλεσης των προγραμμάτων με την αύξηση του ρολογιού της μνήμης. Η βελτίωση είναι μικρή καθώς μόνο ένα μικρό ποσοστό των προσπελάσεων καταλήγουν στην μνήμη RAM (μόνο τα L2 misses). Έτσι, διακρίνουμε ότι τα benchmarks που έχουν μεγαλύτερο L2 miss rate (υποθέτοντας ότι κάνουν περίπου τις ίδιες πορσπελάσεις) έχουν πιο μεγάλη μείωση του χρόνου εκτέλεσης.

## Βήμα 2

Εδώ ζητείται η αλλαγή κάποιων παραμέτρων της ιεραρχίας μνήμης, ώστε το CPI των εντολών να προσεγγίζει το ιδανικό **1**.

* Αρχικά, παραθέτουμε διαγράμματα που δείχνουν την επίδραση κάθε παράγοντα ξεχωριστά στην απόδοση του κάθε Benchmark. Για τη δημιουργία αυτών, κρατάμε σταθερούς όλους τους υπόλοιπους παράγοντες στις default τιμές και μεταβάλλουμε κάθε φορά την παράμετρο που μας ενδιαφέρει.

![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/DL1-A.jpg)
![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/DL1-S.jpg)
![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/IL1-S.jpg)
![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/IL1-A.jpg)
![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/L2-A.jpg)
![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/L2-S.jpg)
![alt text](https://github.com/DimKon2001/ArchLab/blob/main/Lab2/plots/LS.jpg)


 1. **bzip** Mένει instruction cache associativity 1

    Στο συγκεκριμένο benchmark παρατηρήθηκε πως με τις default τιμές το miss rate της instruction cache ήταν σχεδόν μηδενικό, 
    οπότε διατηρήθηκαν οι default τιμές ως προς το μέγεθος και τo associativity της. 
    
    Στην συνέχεια διπλασιάστηκε και 
    υποδιπλασιάστηκε το μέγεθος του cache line, ενός παράγοντα που επηρεάζει και τους 3 τύπους cache misses της εργασίας και παρατηρήθηκε πως με τα default cache sizes βελτιώθηκαν και τα 3 cache miss rates, οπότε το cache line size έγινε 128. 

    |  benchmarks        |system.cpu.cpi|system.cpu.dcache.overall_miss_rate::total|	system.cpu.icache.overall_miss_rate::total|	system.l2.overall_miss_rate::total|
    |:------------------:|:----------:|:-------:|:-------:|:-------|
    |bzip_DL1_S_64_LS_128|	1.666573	|0.014359	|0.000067	|0.173845|
    |bzip_DL1_S_64_LS_64 |	1.679650	|0.014798	|0.000077	|0.282163|

    
    Στην συνέχεια, το προβλήματα των misses για την data cache, την instruction cache και την l2 cache είναι ανεξάρτητα(DL1_S_64_LS_128).

    |  benchmarks        |system.cpu.cpi|system.cpu.dcache.overall_miss_rate::total|	system.cpu.icache.overall_miss_rate::total|	system.l2.overall_miss_rate::total|
    |:------------------:|:----------:|:-------:|:-------:|:-------|
    |bzip_DL1_S_128_DL1_A_1	|1.617513	|0.009068	|0.000067	|0.284306|
    |bzip_DL1_S_128_DL1_A_2	|1.634732	|0.010771	|0.000067	|0.236030|
    |bzip_DL1_S_128_DL1_A_4	|1.626013	|0.009841	|0.000067	|0.260142|
    |bzip_DL1_S_128_DL1_A_8	|1.617513	|0.009068	|0.000067	|0.284306|
    |bzip_DL1_S_128_DL1_A_16|1.617513 |0.009068 |0.000067 |0.284306|
    |bzip_DL1_S_64_DL1_A_1	|1.643747	|0.012206	|0.000067	|0.206465|
    |bzip_DL1_S_64_DL1_A_2	|1.666573	|0.014359	|0.000067	|0.173845|
    |bzip_DL1_S_64_DL1_A_4	|1.649833	|0.012826	|0.000067	|0.195893|
    |bzip_DL1_S_64_DL1_A_8	|1.643747	|0.012206	|0.000067	|0.206465|
    |bzip_DL1_S_64_DL1_A_16 |1.643747 |0.012206 |0.000067 |0.206465|

    Επιλέχθηκε dcache size = 128kb και associativity = 8.

      Tέλος για την l2 cache (DL1_S_64_LS_128_DL1_S_128_DL1_A_8).  

      |  benchmarks       |system.cpu.cpi|system.cpu.dcache.overall_miss_rate::total|	system.cpu.icache.overall_miss_rate::total|	system.l2.overall_miss_rate::total|
      |------------------:|:-------:|:-------:|:-------:|:-------|
      |bzip_L2_S_1_L2_A_1	|1.681008	|0.009068	|0.000067	|0.419381|
      |bzip_L2_S_1_L2_A_2	|1.650592	|0.009070	|0.000067	|0.359686|
      |bzip_L2_S_1_L2_A_4	|1.643458	|0.009070	|0.000067	|0.341216|
      |bzip_L2_S_1_L2_A_8	|1.641576	|0.009071	|0.000067	|0.333352|
      |bzip_L2_S_1_L2_A_16|	1.640234|	0.009071|	0.000067|	0.329016|
      |bzip_L2_S_2_L2_A_1	|1.640652	|0.009069	|0.000067	|0.327909|
      |bzip_L2_S_2_L2_A_2	|1.625099	|0.009068	|0.000067	|0.300075|
      |bzip_L2_S_2_L2_A_4	|1.616975	|0.009067	|0.000067	|0.284854|
      |bzip_L2_S_2_L2_A_8	|1.617513	|0.009068	|0.000067	|0.284306|
      |bzip_L2_S_2_L2_A_16|	1.618032|	0.009068|	0.000067|	0.284324|
      |bzip_L2_S_4_L2_A_1	|1.602512	|0.009062	|0.000067	|0.259208|
      |bzip_L2_S_4_L2_A_2	|1.600258	|0.009050	|0.000067	|0.253120|
      |bzip_L2_S_4_L2_A_4	|1.599761	|0.009050	|0.000067	|0.252853|
      |bzip_L2_S_4_L2_A_8	|1.599575	|0.009058	|0.000067	|0.252290|
      |bzip_L2_S_4_L2_A_16|	1.598536|	0.009066|	0.000067|0.251077|

      Επιλέχθηκε l2cache size = 4MB και associativity = 16.

      Το κόστος για την αύξηση του line size είναι σχεδόν μηδενικό, οπότε επιλέγεται ξανά line_size = 128, όμως για την dcache παρατηρείται πως δεν
      απαιτείται associativity 8, αλλά πως και το associativity 1 δίνει το ίδιο CPI με ένα μόνο συγκριτή.
      Τέλος με χρήση l2 cache 2MB με associativity 4 το κόστος για την l2 είναι λιγότερο από το 1/2, ενώ το cpi είναι μόνο 2% λιγότερο σε σχέση με την ακριβή υλοποίηση (το miss rate της l2 αυξάνεται λιγότερο από 10%).
      
      Aκόμη πιο φθηνές υλοποιήσεις προκύπτουν με:

      Για dcache size = 16KB και associativity = 2
      system.cpu.dcache.overall_miss_rate::.cpu.data     0.012207

      Για dcache size = 16KB και associativity = 16
      system.cpu.dcache.overall_miss_rate::total     0.012206 
    
      Για direct mapped 8KB icache (τα icache misses είναι πολύ λίγα και σε απόλυτο αριθμό).
      system.cpu.icache.overall_miss_rate::.cpu.inst     0.000445 

      Για 2 way associative 16kb icache με μισό κόστος
      system.cpu.icache.overall_miss_rate::total     0.000078


2. **mcf**
    2. **mcf** 
    Στο συγκεκριμένο benchmark παρατηρήθηκε πως με τις default τιμές το miss rate της instruction cache ήταν αρκετά μεγάλο.

    |  benchmarks       |system.cpu.cpi|system.cpu.dcache.overall_miss_rate::total|	system.cpu.icache.overall_miss_rate::total|	system.l2.overall_miss_rate::total|
    |------------------:|:-------:|:-------:|:-------:|:-------|
    |specmcf_LS_128     | 	1.330534 |	**0.001384**|	0.035212	|0.020416|
    |specmcf_LS_64	     | 1.299095	 |0.002108	|0.023612	 |0.055046|
    |specmcf_LS_32	     | 1.260085	 |0.003208	|**0.013171** |	0.159189|

    Με αύξηση του LS αυξάνονταν το miss rate της icache και μειώνονταν αυτό της dcache, γεγονός που οδήγησε στο συμπέρασμα πως τα 
    μεγαλύτερα blocks αύξησαν τα capacity misses στην icache. Έτσι για την μείωση του icache miss rate διπλασιάστηκε η icache.

    |  benchmarks       |system.cpu.cpi|system.cpu.dcache.overall_miss_rate::total|	system.cpu.icache.overall_miss_rate::total|	system.l2.overall_miss_rate::total|
    |------------------:|:-------:|:-------:|:-------:|:-------|
    | specmcf_LS_128_DL1_S_128_IL1_S_64	| 1.123502|	**0.001180 **|	**0.000020** |	0.624600 |
    | specmcf_LS_32_DL1_S_128_IL1_S_64	 | 1.178559 |	 0.003043	   | 0.000026      |	0.869800 |
    | specmcf_LS_64_DL1_S_128_IL1_S_64	 | 1.155171 |	 0.001932	   | 0.000018      |	0.776058 |
    | specmcf_LS_16_DL1_S_128_IL1_S_64	 | 1.314712 |	 0.004511	   | 0.000035      |	0.918531 | 

    Τελικά επιλέχθηκε line size = 128, ενώ η dcache έγινε και αυτή 128KB.
    Eπειδή το miss rate σχεδόν εκμηδενίστηκε οι υπόλοιποι παράγοντες της icache έμειναν σταθεροί.

    Στην συνέχεια για την εύρεση του associativity:

    |  benchmarks       |system.cpu.cpi|system.cpu.dcache.overall_miss_rate::total
    |------------------:|:-------:|:-------:|
    |specmcf_DL1_A_4_S_128_IL1_A_2_S_32_LS_128	|1.329491	|0.001120	 | 
    |specmcf_DL1_A_1_S_128_IL1_A_2_S_32_LS_128	|1.333098	|0.001772	 | 
    |specmcf_DL1_A_16_S_128_IL1_A_2_S_32_LS_128 | 1.329359|0.001104  | 
    |specmcf_DL1_A_8_S_128_IL1_A_2_S_32_LS_128	|1.329424	|0.001106	 | 
    |specmcf_DL1_A_2_S_128_IL1_A_2_S_32_LS_128	|1.329652	|0.001180	 | 


    |  benchmarks       |system.cpu.cpi|system.cpu.dcache.overall_miss_rate::total
    |------------------:|:-------:|:-------:|
    |specmcf_DL1_A_4_S_128_IL1_A_2_S_32_LS_128	|1.329491	|0.001120	 | 
    |specmcf_DL1_A_1_S_128_IL1_A_2_S_32_LS_128	|1.333098	|0.001772	 | 
    |specmcf_DL1_A_16_S_128_IL1_A_2_S_32_LS_128 | 1.329359|0.001104  | 
    |specmcf_DL1_A_8_S_128_IL1_A_2_S_32_LS_128	|1.329424	|0.001106	 | 
    |specmcf_DL1_A_2_S_128_IL1_A_2_S_32_LS_128	|1.329652	|0.001180	 | 

    Επιλέχθηκε associativity = 16, το οποίο όμως έχει πολύ μεγάλο κόστος. Μια πιο οικονομική λύση, χωρίς σχεδόν καμία επίδραση στην απόδοση θα ήταν η χρήση direct mapped ή 2 way set associative l2 cache. Mια ακόμη πιο οικονομική λύση θα ήταν η διατήρηση της dcahce στα 64kb 2 way set associsiative με miss rate = 0.001384 (μισό κόστος). Στις παρακάτω προσομοιώσεις έχει αλλαχθεί το associativity της icache το οποίο όμως δεν επηρεάζει τα misses στην dcache, ενώ επειδή και τα overall misses με associativity 2
    είναι λίγα, μπορούμε να πούμε πως δεν έχει επίδραση στην l2.
        
    |  benchmarks       |system.cpu.cpi|system.cpu.dcache.overall_miss_rate::total|	system.cpu.icache.overall_miss_rate::total|	system.l2.overall_miss_rate::total|
    |------------------:|:-------:|:-------:|:-------:|:-------|
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_1_S_4_LS_128	|1.123167	|	0.001180	| 0.000013 | 0.622356 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_2_S_4_LS_128	|1.123167	|	0.001180	| 0.000013 | 0.622356 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_2_S_2_LS_128	|1.123623	|	0.001180	| 0.000013 | 0.630115 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_8_S_1_LS_128	|1.127683	|	0.001180	| 0.000013 | 0.704042 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_1_S_1_LS_128	|1.130283	|	0.001180	| 0.000013 | 0.751377 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_8_S_2_LS_128	|1.123454	|	0.001180	| 0.000013 | 0.628332 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_8_S_4_LS_128	|1.123167	|	0.001180	| 0.000013 | 0.622356 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_4_S_1_LS_128	|1.127885	|	0.001180	| 0.000013 | 0.705200 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_16_S_4_LS_128	|1.123167	|	0.001180	| 0.000013 | 0.622356 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_4_S_2_LS_128	|1.123471	|	0.001180	| 0.000013 | 0.629177 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_1_S_2_LS_128	|1.127125	|	0.001180	| 0.000013 | 0.698755 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_2_S_1_LS_128	|1.127838	|	0.001180	| 0.000013 | 0.706889 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_16_S_2_LS_128	|1.123564	|	0.001180	| 0.000013 | 0.629396 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_4_S_4_LS_128	|1.123167	|	0.001180	| 0.000013 | 0.622356 |
    |specmcf_DL1_A_2_S_128_IL1_A_16_S_64_L2_A_16_S_1_LS_128	|1.127567	|	0.001180	| 0.000013 | 0.704167 |

    
    Για την l2 το μικρότερο miss rate επιτυγχάνεται για size = 4MB και associativity = 16, ενώ η υλοποίηση με την καλύτερη σχέση κόστους-miss rate είναι αυτή με size = 2MB και associativity = 2.

3. **jeng**

Με αύξηση του line size βελτιώθηκαν και τα 3 cache miss rates και γι'αυτό επιλέχθηκε cahce line size = 128, ενώ το icache miss rate σχεδόν εκμηδενίστηκε, οπότε η icache διατηρήθηκε στις default τιμές.

|  benchmarks       |system.cpu.cpi|system.cpu.dcache.overall_miss_rate::total|	system.cpu.icache.overall_miss_rate::total|	system.l2.overall_miss_rate::total|
|------------------:|:-------:|:-------:|:-------:|:-------|
|specsjeng_LS_32	        |17.653706	|0.243654	|0.000023	|0.999988|
|specsjeng_LS_128        |	6.799471	|0.060922	|0.000015	|0.999825|

Mε line size  128 παρατηρήθηκε μεγάλη μείωση στο CPI με πολύ μικρό κόστος, ενώ το miss rate στην instruction cache
σχεδόν εκμηδενίστηκε, οπότε η instruction cache διατηρήθηκε στις default τιμές.


|  benchmarks       |system.cpu.cpi|system.cpu.dcache.overall_miss_rate::total|	system.cpu.icache.overall_miss_rate::total|	system.l2.overall_miss_rate::total|
|------------------:|:-------:|:-------:|:-------:|:-------|
|specsjeng_DL1_S_32_DL1_A_2_LS_128	|6.799471|	0.060926|	0.000015	|0.999686 |
|specsjeng_DL1_S_32_DL1_A_4_LS_128	|6.799674|	0.060918|	0.000015	|0.999942 |
|specsjeng_DL1_S_32_DL1_A_8_LS_128	|6.799674|	0.060918|	0.000015	|0.999945 |
|specsjeng_DL1_S_64_DL1_A_2_LS_128	|6.799471|	0.060922|	0.000015	|0.999825 |
|specsjeng_DL1_S_64_DL1_A_4_LS_128	|6.799536|	0.060918|	0.000015	|0.999949 |
|specsjeng_DL1_S_64_DL1_A_8_LS_128	|6.799674|	0.060918|	0.000015	|0.999949 |
|specsjeng_DL1_S_128_DL1_A_2_LS_128	|6.799362|	0.060921|	0.000015	|0.999856 |
|specsjeng_DL1_S_128_DL1_A_4_LS_128	|6.799362|	0.060918|	0.000015	|0.999952 |
|specsjeng_DL1_S_128_DL1_A_8_LS_128	|6.799609|	0.060918|	0.000015	|0.999952 |

Για την dcache παρατηρήθηκε ότι το associativity πάνω από 2 και dcache size πάνω από 32ΚΒ δεν είχαν επίδραση στο CPI. 
Το μικρότερο miss rate αντιστοιχεί σε 4 set associative 32kb dcache. Για πιο οικονομική κατασκευή επιλέγεται direct mapped 8kb dcache (1/4 του μεγέθους-κόστους και μόνο 1 συγκριτή).

|  benchmarks        |system.cpu.dcache.overall_miss_rate::total|	
|------------------:|:-------:|
|specsjeng_DL1_A_1_S_8_IL1_A_1_S_8_L2_A_1_S_1_LS_128  | 0.062027|		
|specsjeng_DL1_A_1_S_32_IL1_A_1_S_16_L2_A_1_S_1_LS_128|	0.062027|

Για πιο οικονομική κατασκευή παρατηρήθηκε πως μια direct mapped 8kb icache είχε σχεδόν το ίδιο miss rate με την default
με πολύ μικρότερο κόστος (1/4 του μεγέθους).

|  benchmarks       |	system.cpu.icache.overall_miss_rate::total|
|------------------:|:-------:|
|specsjeng_DL1_A_1_S_8_IL1_A_1_S_8_L2_A_1_S_4_LS_128	|   0.00028 |													
|specsjeng_DL1_A_1_S_32_IL1_A_1_S_16_L2_A_1_S_4_LS_128|	  0.000275|					
|specsjeng_DL1_A_1_S_128_IL1_A_1_S_32_L2_A_1_S_2_LS_128|	1.6E-05	|

Aπό τα παραπάνω φαίνεται το μεγάλο miss rate της l2 cache, το οποίο θα αντιμετωπιστεί με αύξηση του size της l2.
Συγκεκριμένα προκύπτει: 

specsjeng_FINALDL1_A_4_S_32_IL1_A_2_S_32_L2_A_8_S_2_LS_128 
system.cpu.cpi                               6.799380
specsjeng_FINALDL1_A_4_S_32_IL1_A_2_S_32_L2_A_8_S_4_LS_128 
system.cpu.cpi                               6.795293
specsjeng_FINALDL1_A_4_S_32_IL1_A_2_S_32_L2_A_16_S_4_LS_128
system.cpu.cpi                               6.79589
specsjeng_FINALDL1_A_4_S_32_IL1_A_2_S_32_L2_A_4_S_2_LS_128
system.cpu.cpi                               6.799362   
specsjeng_FINALDL1_A_4_S_32_IL1_A_2_S_32_L2_A_1_S_1_LS_128
system.cpu.cpi                               6.801166

Φαίνεται πως υπάρχει ελάχιστη επίδραση της l2 στο CPI. Σε μια οικονομική υλοποίηση θα χρησιμοποιηθεί l2 size = 1MB και associativity = 1

4. **hmmer**

* _Data Cache_: 
  * Με βάση τα διαγράμματα παρατηρούμε ότι το **associativity** της dcache για το συγκεκριμένο benchmark φαίνεται να επηρεάζει τα misses και άρα και την απόδοση. Αυτό μπορεί να εξηγηθεί καθώς αυξάνωντας το associativity, μειώνονται τα conflict misses. Παρατηρούμε επίσης ότι στο συγκεκριμένο benchmark η αύξηση έχει νόημα μέχρι την τιμή 4 καθώς αν επιλέξουμε την τιμή 8 δεν φαίνεται να κερδίζουμε επιπλέον σε απόδοση ενώ θα "πληρώσουμε" παραπάνω το κόστος της αύξησης του associativity.
  
  * Όσον αφορά το **size**, παρατηρούμε από το σχετικό διάγραμμα ότι όσο αυξάνεται το μέγεθος της cache βελτιώνεται η απόδοση. Έτσι, για μέγεθος 128kB έχουμε μία πολύ καλή μείωση των misses.

* _Instruction Cache_: 
  * Με βάση τα διαγράμματα και τα αποτελέσματα του πρώτου βήματος, παρατηρούμε ότι το **associativity** της icache φαίνεται να παρουσιάζει την μεγαλύτερη θετική επίδραση στην απόδοση όταν είναι 4. Όμως, καθώς το miss rate σε αυτό το benchmark είναι ήδη πολύ χαμηλό για την icache, δεν αναμένεται μία τέτοια βελτίωση να είναι δραματική.
  
  * Και εδώ αύξηση του **size** οδηγεί σε καλύτερα αποτελέσματα αλλά και πάλι δεν θα υπάρχει μεγάλη διαφορά λόγω του μικρού miss rate.

* _L2 Cache_:

  * Με βάση τα διαγράμματα και τα αποτελέσματα του πρώτου βήματος, παρατηρούμε ότι ούτε η αλλαγή του associativity ούτε του size οδηγούν σε βελτίωση της απόδοσης.

* _Line Size_:

  * Στα διαγράμματα φαίνεται ότι το line-size, επίσης δεν επηρεάζει δραματικά την επίδοση του προγράμματος, όμως γνωρίζουμε ότι με την αύξησή του εποφελούνται προγράμματα με καλύτερο locality καθώς μειώνονται τα compulsory misses.

Μέτα από την ανάλυση αυτή, έγινε επιλογή line_size = 128, size=128kB για όλες τις L1 caches και 4ΜΒ για την L2 και εκτέλεση κάποιων προσομοιώσεων για τις υπόλοιπες παραμέτρους, τα αποτελέσματα των οποίων φαίνονται παρακάτω:

|       Parameters           |	system.cpu.cpi |	
|----------------------------|:---------------:|
|DL1: A=2 IL1: A=1 L2: A= 16 |   	1.180639
|DL1: A=2 IL1: A=1 L2: A= 4	 |   1.180639
|**DL1: A=4 IL1: A=4 L2: A= 16** |   **1.179746**
|DL1: A=4 IL1: A=1 L2: A= 8	 |   1.180462
|DL1: A=2 IL1: A=2 L2: A= 4	 |   1.179925
|DL1: A=1 IL1: A=2 L2: A= 4	 |   1.187221
|DL1: A=2 IL1: A=1 L2: A= 8	 |   1.180639
|DL1: A=2 IL1: A=2 L2: A= 8	 |   1.179925
|DL1: A=4 IL1: A=1 L2: A= 16 |   	1.180462
|DL1: A=2 IL1: A=4 L2: A= 4	 |   1.179925
|DL1: A=2 IL1: A=4 L2: A= 8	 |   1.179925
|DL1: A=2 IL1: A=4 L2: A= 16 |   	1.179925
|**DL1: A=8 IL1: A=8 L2: A= 32** |   	**1.179450**

* Οπότε η επιλογή που φαίνεται να οδηγεί στο καλύτερο CPI (καλύτερο από εκείνο με τις default συνθήκες:  1.187917) από τις παραπάνω είναι Associativity = 8 για τις L1 Caches και 32 για την L2, με πολύ μικρή διαφορά από την επιλογή των μισών Associativities, που είναι και πιο οικονομική.


5. **lbm**

* _Data Cache_: 
  * Με βάση τα διαγράμματα παρατηρούμε ότι το **associativity** της dcache όταν αυξάνει από 1 σε 2, βελτιώνει αρκετά τα misses αλλά περαιτέρω αύξηση δεν φαίνεται να οδηγεί σε μεγάλη βελτίωση.
  
  * Όσον αφορά το **size**, παρατηρούμε από το σχετικό διάγραμμα ότι όσο αυξάνεται το μέγεθος της cache και εδώ βελτιώνεται η απόδοση. Βέβαια είναι μικρή βελτίωση σε σχέση με το προηγούμενο benchamrk.

* _Instruction Cache_: 
  * Το διάγραμμα του μεγέθους (**size**) δείχνει ότι το miss rate της instruction cache είναι σχεδόν μηδέν, οπότε η βελτίωση εκεί δεν θα έχει μεγάλη διαφορά για το συγκεκριμένο benchmark. Γνωρίζουμε πάντως ότι θεωρητικά όσο μεγαλύτερη η cache τόσο λιγότερα τα misses.
  
  * Aύξηση του **associativity** φαίνεται να μην έχει επίδραση καθώς το miss rate όπως ήδη αναφέρθηκε είναι ήδη χαμηλό.

  Το συγκεκριμένο benchmark εκτελεί [προσομοίωση ρευστών](https://en.wikipedia.org/wiki/Lattice_Boltzmann_methods), οπότε εκτελεί αλγεβρικές πράξεις. Επομένως αναμένεται να έχει καλό locality και επίσης να περιέχει λίγες branch, για αυτό και έχει πολύ χαμηλό icache miss rate.

* _L2 Cache_:

  * Με βάση τα διαγράμματα το benchmark αυτό φαίνεται να έχει πάντα αστοχία όποτε φτάνει στην L2 cache ανεξαρτήτως **size** και **associativity**.

* _Line Size_:

  * Όπως είναι φανερό από το διάγραμμα και δεδομένου ότι το πρόγραμμα έχει καλό locality αύξηση του line size οδηγεί σε καλύτερα CPI.

Μέτα από την ανάλυση αυτή, έγινε επιλογή line_size = 128, size=128kB για όλες τις L1 caches και 4ΜΒ για την L2 και εκτέλεση κάποιων προσομοιώσεων για τις υπόλοιπες παραμέτρους, τα αποτελέσματα των οποίων φαίνονται παρακάτω:

|       Parameters           |	system.cpu.cpi |	
|----------------------------|:---------------:|
|DL1: A=8 IL1: A=8 L2: A=32	 |   2.576600	
|DL1: A=4 IL1: A=4 L2: A=16	 |   **2.576597**	
|DL1: A=2 IL1: A=4 L2: A=16	 |   **2.576597**
|DL1: A=2 IL1: A=1 L2: A=16	 |   **2.576597**
|DL1: A=1 IL1: A=1 L2: A=4   |   2.586108	
|DL1: A=2 IL1: A=2 L2: A=16	 |   **2.576597**	
|DL1: A=2 IL1: A=1 L2: A=4   |   2.576600	
|DL1: A=1 IL1: A=2 L2: A=16	 |   2.586045	
|DL1: A=2 IL1: A=4 L2: A=4   |   2.576600	
|**DL1: A=4 IL1: A=1 L2: A=8**   |   **2.576597**
|DL1: A=4 IL1: A=4 L2: A=8   |   **2.576597**	
|DL1: A=1 IL1: A=1 L2: A=16	 |   2.586096	
|DL1: A=1 IL1: A=4 L2: A=4   |   2.586045	
|DL1: A=2 IL1: A=1 L2: A=8   |   **2.576597**
|DL1: A=4 IL1: A=2 L2: A=16	 |   **2.576597**	
|DL1: A=2 IL1: A=2 L2: A=4   |   2.576600 	

* Όπως φαίνεται, υπάρχουν πολλές επιλογές που οδηγούν στο μικρότερο CPI, το οποίο όμως αν και χωρίς μεγάλη διαφορά, είναι μικρότερο από εκείνο των default παραμέτρων (3.4934). Μπορούμε να επιλέξουμε την πιο οικονομική επιλογή απότις παραπάνω που είναι Associativity = 4 για την L1 dcache και 1 για την icache και 8 για την L2.

## Βήμα 3
* Αρχικά, μελετάμε το κόστος κατασκευής.
Για τις διάφορες ιεραρχίες cache ισχύει πως το κόστος ανά byte της l1 είναι μεγαλύτερο κατά μια τάξη μεγέθους από αυτό της l2 για την ίδια χωρητικότητα. Aυτό εξηγείται από το γεγονός ότι ο ρόλος του πρώτου επιπέδου cache είναι η γρήγορη πρόσβαση, οπότε τα τρανζιστορ της πρέπει να έχουν την ταχύτερη δυνατή απόκριση, ανεβάζοντας το κόστος. Ακόμη με διπλασιασμό της χωρητικότητας μιας cache διπλασιάζεται και η τιμή της, γιατί απαιτούνται περισσότερα bits/πυρίτιο για την αποθήκευση των πληροφοριών, όσο και για τον μεγαλύτερο πολυπλέκτη. Με διπλασιασμό του block size στην ίδια χωρητικότητα cache απαιτούνται περίπου τα μισά tag bits (μισά blocks, κάθε block θέλει +1 tag bit) και παραπάνω καλώδια μεταξύ των επιπέδων και μεγαλύτεροι write buffers, για αυτό θεωρούμε πως ο διπλασιασμός των blocks έχει αμελητέα επίδραση στο κόστος. Τέλος για μια n associative cache απαιτούνται n συγκριτές (για παράλληλη σύγκριση των tags) επομένως και περισσότερες πύλες, γεγονός που αυξάνει λίγο το κόστος.

Θεωρώντας το κόστος μιας l2 cache c/kB και ενός συγκριτή d/kB το κόστος μιας cache είναι:

* Cost = (10*size(l1) + size(l2))*c + (associativity(l1i)  + associativity(l1d) + associativity(l2) )*d

Μπορούμε να θεωρήσουμε ότι το d είναι πολύ μικρότερο του c και έτσι να το αγνοήσουμε για αυτήν την μελέτη.


* Ακόμα, πρέπει να λάβουμε υπόψη μας σε αυτά και την κατανάλωση ισχύος. Γενικότερα όσο περισσότερο hardware προσθέτουμε, τόσο περισσότερο αυξάνεται αυτή. Θεωρούμε ότι είναι ανάλογη του associativity, και του block size, καθώς στη μία περίπτωση αυξάνονται όπως είπαμε τα κυκλώματα ελέγχου και στην άλλη η μνήμη θα πρέπει να σηκώνει περισσότερες λέξεις ανά μπλοκ. Εξαρτάται επίσης από το execution time.


* Σε αυτά θα πρέπει να προστεθεί και το execution time. Βέβαια, ανάλογα την εφαρμογή, άλλες φορές είναι πιο σηαμντική η ταχύτητα σε μέγεθος nanosecond και άλλες όχι και τόσο. Για τα συγκεκριμένα Benchamrks, ίσως με εξαίρεση το mcf που πραγματεύεται [χρονοπροργαμμτισμό οχημάτων](https://www.spec.org/cpu2006/Docs/429.mcf.html), δεν κρίνεται ζωτικής σημασίας ο χρόνος εκτέλεσης, αλλά απλά σημαντικός.

Ένας τύπος που προτείνουμε τελικά για το συνολικό κόστος, προσθέτοντας τους τρεις όρους είναι (size σε kB):

total_cost = (10 * (size(l1d) + size(l1i)) + size(l2)) * c1 + (assoc(l1i) + assoc(l2) + assoc(l1d) + blocksize) * exec_time * c2 + exec_time * c3

Έτσι, ανάλογα με την εφαρμογή επιλέγουμε τα c1, c2, c3. Αυθαίρετα, έστω c1 = 3, c2 = 1, c3 = 2

* Για τις επιλογές του βήματος 2 θα είναι:

| Benchmark | cost    |
|----------:|--------:|
| bzip2     |         |
| sjeng     |         |
| hmmer     | 19783.9 |
|   mcf     |         |
|  libm     | 19698.3 |









